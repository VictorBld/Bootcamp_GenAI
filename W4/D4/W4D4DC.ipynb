{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ABUE_JA6E3b_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger les données (adapter le chemin si besoin)\n",
        "df = pd.read_csv(\"household_power_consumption.txt\", sep=\";\", na_values=\"?\")\n",
        "\n",
        "# Afficher les premières lignes\n",
        "print(df.head())\n",
        "\n",
        "# Vérifier les types de données\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSODyVunFOgT",
        "outputId": "4550e619-0f7b-493d-a3cd-7d97ca7704c7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Date      Time  Global_active_power  Global_reactive_power  Voltage  \\\n",
            "0  16/12/2006  17:24:00                4.216                  0.418   234.84   \n",
            "1  16/12/2006  17:25:00                5.360                  0.436   233.63   \n",
            "2  16/12/2006  17:26:00                5.374                  0.498   233.29   \n",
            "3  16/12/2006  17:27:00                5.388                  0.502   233.74   \n",
            "4  16/12/2006  17:28:00                3.666                  0.528   235.68   \n",
            "\n",
            "   Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
            "0              18.4             0.0             1.0            17.0  \n",
            "1              23.0             0.0             1.0            16.0  \n",
            "2              23.0             0.0             2.0            17.0  \n",
            "3              23.0             0.0             1.0            17.0  \n",
            "4              15.8             0.0             1.0            17.0  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 178861 entries, 0 to 178860\n",
            "Data columns (total 9 columns):\n",
            " #   Column                 Non-Null Count   Dtype  \n",
            "---  ------                 --------------   -----  \n",
            " 0   Date                   178861 non-null  object \n",
            " 1   Time                   178861 non-null  object \n",
            " 2   Global_active_power    178852 non-null  float64\n",
            " 3   Global_reactive_power  178852 non-null  float64\n",
            " 4   Voltage                178852 non-null  float64\n",
            " 5   Global_intensity       178852 non-null  float64\n",
            " 6   Sub_metering_1         178852 non-null  float64\n",
            " 7   Sub_metering_2         178852 non-null  float64\n",
            " 8   Sub_metering_3         178851 non-null  float64\n",
            "dtypes: float64(7), object(2)\n",
            "memory usage: 12.3+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing\n",
        "df[\"Datetime\"] = pd.to_datetime(df[\"Date\"] + \" \" + df[\"Time\"], format=\"%d/%m/%Y %H:%M:%S\")\n",
        "\n",
        "df.drop([\"Date\", \"Time\"], axis=1, inplace=True)\n",
        "\n",
        "df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv09Ajr_FWy0",
        "outputId": "2baff36f-b77e-4e4b-d7d5-60702fa2bcd1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 178851 entries, 0 to 178859\n",
            "Data columns (total 8 columns):\n",
            " #   Column                 Non-Null Count   Dtype  \n",
            "---  ------                 --------------   -----  \n",
            " 0   Global_active_power    178851 non-null  float64\n",
            " 1   Global_reactive_power  178851 non-null  float64\n",
            " 2   Voltage                178851 non-null  float64\n",
            " 3   Global_intensity       178851 non-null  float64\n",
            " 4   Sub_metering_1         178851 non-null  float64\n",
            " 5   Sub_metering_2         178851 non-null  float64\n",
            " 6   Sub_metering_3         178851 non-null  float64\n",
            " 7   Datetime               178851 non-null  int64  \n",
            "dtypes: float64(7), int64(1)\n",
            "memory usage: 12.3 MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = \"Global_active_power\"\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "df_scaled = scaler.fit_transform(df)\n",
        "\n",
        "df_scaled = pd.DataFrame(df_scaled, columns=df.columns)\n",
        "\n",
        "X = df_scaled.drop(columns=[target_col]).values\n",
        "y = df_scaled[target_col].values\n",
        "\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]"
      ],
      "metadata": {
        "id": "9VwimxNFFfDf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertion des données tensors PyTorch\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 64\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "test_dataset = TensorDataset(X_test_t, y_test_t)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "vq2KxgFCFlko"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=50, num_layers=1):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x.unsqueeze(1))\n",
        "        return self.fc(lstm_out[:, -1, :])\n",
        "\n",
        "# Initialiser le modèle\n",
        "input_size = X_train.shape[1]\n",
        "model = LSTMModel(input_size)"
      ],
      "metadata": {
        "id": "Gh-R5kUjFurA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(X_batch)\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9S0Onn-F22q",
        "outputId": "dcac00dc-b330-4787-b2e4-19d425c523c4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.0011\n",
            "Epoch 2/10, Loss: 0.0000\n",
            "Epoch 3/10, Loss: 0.0000\n",
            "Epoch 4/10, Loss: 0.0000\n",
            "Epoch 5/10, Loss: 0.0000\n",
            "Epoch 6/10, Loss: 0.0000\n",
            "Epoch 7/10, Loss: 0.0000\n",
            "Epoch 8/10, Loss: 0.0000\n",
            "Epoch 9/10, Loss: 0.0000\n",
            "Epoch 10/10, Loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "model.eval()\n",
        "y_pred_list = []\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        y_pred = model(X_batch)\n",
        "        y_pred_list.extend(y_pred.cpu().numpy().squeeze())\n",
        "\n",
        "y_pred_np = np.array(y_pred_list)\n",
        "y_test_np = y_test.squeeze()\n",
        "\n",
        "r2 = r2_score(y_test_np, y_pred_np)\n",
        "\n",
        "print(f\"R² Score: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnlEKyr5GC_V",
        "outputId": "9d8163ea-f60d-4db6-cd63-47750fa68041"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² Score: 0.9990\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_day(model, last_day_data):\n",
        "    model.eval()\n",
        "    last_day_tensor = torch.tensor(last_day_data, dtype=torch.float32).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        prediction = model(last_day_tensor)\n",
        "    return prediction.item()\n",
        "\n",
        "# Exemple d'utilisation\n",
        "last_day = X_test[-1]  # Dernier jour de test\n",
        "next_day_pred = predict_next_day(model, last_day)\n",
        "\n",
        "# Inverser la normalisation\n",
        "next_day_pred_actual = scaler.inverse_transform([[0] * (X.shape[1]) + [next_day_pred]])[0][-1]\n",
        "print(f\"Prédiction du prochain jour: {next_day_pred_actual:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmIl9nUVGkqw",
        "outputId": "32fad948-b7ea-4eaf-c7bc-a18886587e5e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prédiction du prochain jour: 1166505813819556096.0000\n"
          ]
        }
      ]
    }
  ]
}